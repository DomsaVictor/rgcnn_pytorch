{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final tests for the journal review. What is tested:\n",
    "    \n",
    "    - get/plot more params (FLOPS, model size etc.)\n",
    "    - PCD vis: GT vs Pred\n",
    "    - Test for all noises combined\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rocon/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports:\n",
    "import time\n",
    "import imports\n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.transforms import FixedPoints, Compose, NormalizeScale, NormalizeRotation, RandomRotate\n",
    "from FilteredShapenetDataset import FilteredShapeNet, ShapeNetCustom\n",
    "from RGCNNSegmentation import seg_model\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import BoundingBoxRotate, label_to_cat\n",
    "from utils import seg_classes\n",
    "\n",
    "from TestModel import ModelTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2048, 3], y=[2048], pos=[2048, 3], category=[1])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "dataset_name = \"Original_2048\"\n",
    "dataset = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", split=\"test\", transform=FixedPoints(2048), categories=seg_classes)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: final_models/2048_seg_clean.pt\n",
      "7413666\n",
      "seg_model(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bias_relus): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1x2048x1024]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 1x2048x50]\n",
      "  )\n",
      "  (conv): ModuleList(\n",
      "    (0): DenseChebConvV2(in_features=22, out_features=128, K=6, bias=True)\n",
      "    (1): DenseChebConvV2(in_features=128, out_features=512, K=5, bias=True)\n",
      "    (2): DenseChebConvV2(in_features=512, out_features=1024, K=3, bias=True)\n",
      "  )\n",
      "  (batch_norm_list_conv): ModuleList(\n",
      "    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (batch_norm_list_fc): ModuleList(\n",
      "    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=50, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model: final_models/2048_seg_bb.pt\n",
      "7413666\n",
      "seg_model(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bias_relus): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1x2048x1024]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 1x2048x50]\n",
      "  )\n",
      "  (conv): ModuleList(\n",
      "    (0): DenseChebConvV2(in_features=22, out_features=128, K=6, bias=True)\n",
      "    (1): DenseChebConvV2(in_features=128, out_features=512, K=5, bias=True)\n",
      "    (2): DenseChebConvV2(in_features=512, out_features=1024, K=3, bias=True)\n",
      "  )\n",
      "  (batch_norm_list_conv): ModuleList(\n",
      "    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (batch_norm_list_fc): ModuleList(\n",
      "    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=50, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model: final_models/2048_seg_rrbb.pt\n",
      "7413666\n",
      "seg_model(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bias_relus): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1x2048x1024]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 1x2048x50]\n",
      "  )\n",
      "  (conv): ModuleList(\n",
      "    (0): DenseChebConvV2(in_features=22, out_features=128, K=6, bias=True)\n",
      "    (1): DenseChebConvV2(in_features=128, out_features=512, K=5, bias=True)\n",
      "    (2): DenseChebConvV2(in_features=512, out_features=1024, K=3, bias=True)\n",
      "  )\n",
      "  (batch_norm_list_conv): ModuleList(\n",
      "    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (batch_norm_list_fc): ModuleList(\n",
      "    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=50, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model: final_models/2048_seg_eig.pt\n",
      "7413666\n",
      "seg_model(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bias_relus): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1x2048x1024]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 1x2048x50]\n",
      "  )\n",
      "  (conv): ModuleList(\n",
      "    (0): DenseChebConvV2(in_features=22, out_features=128, K=6, bias=True)\n",
      "    (1): DenseChebConvV2(in_features=128, out_features=512, K=5, bias=True)\n",
      "    (2): DenseChebConvV2(in_features=512, out_features=1024, K=3, bias=True)\n",
      "  )\n",
      "  (batch_norm_list_conv): ModuleList(\n",
      "    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (batch_norm_list_fc): ModuleList(\n",
      "    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=50, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model: final_models/2048_seg_gauss_rr_bb.pt\n",
      "7413666\n",
      "seg_model(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bias_relus): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1x2048x1024]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 1x2048x50]\n",
      "  )\n",
      "  (conv): ModuleList(\n",
      "    (0): DenseChebConvV2(in_features=22, out_features=128, K=6, bias=True)\n",
      "    (1): DenseChebConvV2(in_features=128, out_features=512, K=5, bias=True)\n",
      "    (2): DenseChebConvV2(in_features=512, out_features=1024, K=3, bias=True)\n",
      "  )\n",
      "  (batch_norm_list_conv): ModuleList(\n",
      "    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (batch_norm_list_fc): ModuleList(\n",
      "    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=50, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model: final_models/2048_seg_gauss_rr_eig.pt\n",
      "7413666\n",
      "seg_model(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (bias_relus): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1x2048x1024]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 1x2048x512]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 1x2048x128]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 1x2048x50]\n",
      "  )\n",
      "  (conv): ModuleList(\n",
      "    (0): DenseChebConvV2(in_features=22, out_features=128, K=6, bias=True)\n",
      "    (1): DenseChebConvV2(in_features=128, out_features=512, K=5, bias=True)\n",
      "    (2): DenseChebConvV2(in_features=512, out_features=1024, K=3, bias=True)\n",
      "  )\n",
      "  (batch_norm_list_conv): ModuleList(\n",
      "    (0): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (batch_norm_list_fc): ModuleList(\n",
      "    (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=50, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "path = \"final_models\"\n",
    "model_names = [\"2048_seg_clean.pt\", \"2048_seg_bb.pt\", \"2048_seg_rrbb.pt\", \"2048_seg_eig.pt\", \"2048_seg_gauss_rr_bb.pt\", \"2048_seg_gauss_rr_eig.pt\"]\n",
    "model_names = [path + \"/\" + model for model in model_names] \n",
    "num_points = 2048\n",
    "input_dim  = 22\n",
    "\n",
    "F = [128, 512, 1024]  # Outputs size of convolutional filter.\n",
    "K = [6, 5, 3]         # Polynomial orders.\n",
    "M = [512, 128, 50]\n",
    "\n",
    "for model in model_names:\n",
    "    net = seg_model(num_points, F, K, M, input_dim, dropout=0.2, reg_prior=False)\n",
    "    net.load_state_dict(torch.load(f\"{imports.curr_path}/{model}\"))\n",
    "    net.eval()\n",
    "    print(f\"\\nModel: {model}\")\n",
    "    print(get_n_params(net))\n",
    "    print(net)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode//final_models/2048_seg_clean.pt\n",
      "torch.Size([1, 2048, 50])\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Test FLOPS counter:\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "with torch.no_grad():\n",
    "    class NetWrapper(torch.nn.Module):\n",
    "        def __init__(self, net):\n",
    "            super(NetWrapper, self).__init__()\n",
    "            self.net = net\n",
    "        \n",
    "        def forward(self, data):\n",
    "            return self.net(data[0], data[1])\n",
    "        \n",
    "\n",
    "    model = \"/final_models/2048_seg_clean.pt\"\n",
    "    pos = dataset[0].pos.unsqueeze(0)\n",
    "    norm = dataset[0].x.unsqueeze(0)\n",
    "    x = torch.cat([pos.type(torch.float32), norm.type(torch.float32)], dim=2)\n",
    "    cat = dataset[0].category\n",
    "    net = seg_model(2048, F, K, M, input_dim, dropout=0.2, reg_prior=False)\n",
    "    print(f\"{imports.curr_path}/{model}\")\n",
    "    net.load_state_dict(torch.load(f\"{imports.curr_path}/{model}\"))\n",
    "    net = net.eval()\n",
    "    out, x , _ = net(x, cat)\n",
    "    print(out.shape)\n",
    "    # net_wrapped = NetWrapper(net)\n",
    "\n",
    "\n",
    "    # data = [x.detach(), cat.detach()]\n",
    "\n",
    "    # flops = FlopCountAnalysis(net_wrapped, data)\n",
    "    # print(f\"Total flops:       {flops.total()}\")\n",
    "    # print(f\"Flops by operator: {flops.by_operator()}\")\n",
    "    # print(f\"Flops by module:   {flops.by_module()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for seg_model:\n\tUnexpected key(s) in state_dict: \"bias_relus.5\", \"batch_norm_list_fc.2.weight\", \"batch_norm_list_fc.2.bias\", \"batch_norm_list_fc.2.running_mean\", \"batch_norm_list_fc.2.running_var\", \"batch_norm_list_fc.2.num_batches_tracked\", \"fc.2.weight\", \"fc.2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/journalTests.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnorris/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/journalTests.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m M \u001b[39m=\u001b[39m [\u001b[39m512\u001b[39m, \u001b[39m128\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnorris/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/journalTests.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m model \u001b[39m=\u001b[39m seg_model(num_points, F, K, M, input_dim, dropout\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, reg_prior\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnorris/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/journalTests.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(model_path))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnorris/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/journalTests.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/workspace/.thesis_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1493\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1494\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1498\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1499\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for seg_model:\n\tUnexpected key(s) in state_dict: \"bias_relus.5\", \"batch_norm_list_fc.2.weight\", \"batch_norm_list_fc.2.bias\", \"batch_norm_list_fc.2.running_mean\", \"batch_norm_list_fc.2.running_var\", \"batch_norm_list_fc.2.num_batches_tracked\", \"fc.2.weight\", \"fc.2.bias\". "
     ]
    }
   ],
   "source": [
    "# Imports:\n",
    "import time\n",
    "import imports\n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.transforms import FixedPoints, Compose, NormalizeScale, NormalizeRotation, RandomRotate\n",
    "from FilteredShapenetDataset import FilteredShapeNet, ShapeNetCustom\n",
    "from RGCNNSegmentation import seg_model\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import BoundingBoxRotate, label_to_cat\n",
    "from utils import seg_classes\n",
    "\n",
    "from TestModel import ModelTester\n",
    "model_path = \"/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/final_models/2048_seg_clean.pt\"\n",
    "\n",
    "num_points = 2048\n",
    "input_dim  = 22\n",
    "\n",
    "F = [128, 512, 1024]  # Outputs size of convolutional filter.\n",
    "K = [6, 5, 3]         # Polynomial orders.\n",
    "M = [512, 128]\n",
    "\n",
    "model = seg_model(num_points, F, K, M, input_dim, dropout=0.2, reg_prior=False)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point 2\n",
    "\n",
    "- GT no rot\n",
    "- GT rot\n",
    "- RGCNN no rot\n",
    "- RGCNN rot\n",
    "- Ours no rot\n",
    "- Ours rot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also thest DGCNN and PointNet: \n",
    "\n",
    "- https://github.com/antao97/dgcnn.pytorch/blob/master/main_cls.py\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity:\n",
    "\n",
    "- Eig - Alex GIT (/ NormalizeRot Pytorch???)\n",
    "- GRAMM + Model - model dim increases\n",
    "- BB\n",
    "- multiview BB - model forward\n",
    "- multiview Eig - model forward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown and time the modules of the alg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noisy dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointCloud with 2048 points., PointCloud with 2048 points., PointCloud with 2048 points., PointCloud with 2048 points.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Points: 512 \t-- 0.004919095039367676\n",
      "Num Points: 1024 \t-- 0.012095909833908082\n",
      "Num Points: 2048 \t-- 0.05739609980583191\n"
     ]
    }
   ],
   "source": [
    "import imports\n",
    "from RGCNNClassification import cls_model\n",
    "num_points = [512, 1024, 2048]\n",
    "\n",
    "\n",
    "F = [128, 512, 1024]  # Outputs size of convolutional filter.\n",
    "K = [6, 5, 3]         # Polynomial orders.\n",
    "M = [512, 128, 50]\n",
    "input_dim = 6\n",
    "\n",
    "\n",
    "for num in num_points:\n",
    "    transform = FixedPoints(num)\n",
    "    dataset = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", transform=transform, categories=seg_classes)\n",
    "    pcd = dataset[0]\n",
    "    pos = pcd.pos.unsqueeze(0)\n",
    "    norm = pcd.x.unsqueeze(0)\n",
    "    x = torch.cat([pos.type(torch.float32), norm.type(torch.float32)], dim=2)\n",
    "    cat = pcd.category\n",
    "    \n",
    "    x = x.to(\"cuda\")\n",
    "    cat = cat.to(\"cuda\")\n",
    "    net = cls_model(num, F, K, M, input_dim, dropout=0.2, reg_prior=False)\n",
    "    net = net.eval()\n",
    "    net = net.to('cuda')\n",
    "    \n",
    "    start = time.time()\n",
    "    for _ in range(1000):\n",
    "        a, b, c = net(x)\n",
    "    stop = time.time()\n",
    "    \n",
    "    print(f\"Num Points: {num} \\t-- {(stop-start)/1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Points: 512 \t-- 0.007277761220932007\n",
      "Num Points: 1024 \t-- 0.015940637350082398\n",
      "Num Points: 2048 \t-- 0.06178945708274841\n"
     ]
    }
   ],
   "source": [
    "num_points = [512, 1024, 2048]\n",
    "\n",
    "\n",
    "F = [128, 512, 1024]  # Outputs size of convolutional filter.\n",
    "K = [6, 5, 3]         # Polynomial orders.\n",
    "M = [512, 128, 50]\n",
    "input_dim = 22\n",
    "\n",
    "\n",
    "for num in num_points:\n",
    "    transform = FixedPoints(num)\n",
    "    dataset = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", transform=transform, categories=seg_classes)\n",
    "    pcd = dataset[0]\n",
    "    pos = pcd.pos.unsqueeze(0)\n",
    "    norm = pcd.x.unsqueeze(0)\n",
    "    x = torch.cat([pos.type(torch.float32), norm.type(torch.float32)], dim=2)\n",
    "    cat = pcd.category\n",
    "    \n",
    "    x = x.to(\"cuda\")\n",
    "    cat = cat.to(\"cuda\")\n",
    "    net = seg_model(num, F, K, M, input_dim, dropout=0.2, reg_prior=True)\n",
    "    net = net.eval()\n",
    "    net = net.to('cuda')\n",
    "    \n",
    "    start = time.time()\n",
    "    for _ in range(1000):\n",
    "        a, b, c = net(x, cat)\n",
    "    stop = time.time()\n",
    "    \n",
    "    print(f\"Num Points: {num} \\t-- {(stop-start)/1000}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rocon/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rocon/Workspace/rgcnn_pytorch/dataset\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import imports\n",
    "# from noise_visualization import get_noisy_pcd, show_pcds\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.transforms import NormalizeScale, Compose, FixedPoints, RandomRotate\n",
    "import numpy as np\n",
    "from utils import seg_classes\n",
    "\n",
    "\n",
    "class VisualizerPCD():\n",
    "    def __init__(self) -> None:\n",
    "        self.pcds_o3d = []        \n",
    "        self.colors = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 1],[0.3, 0.4, 0.6]])\n",
    "        # self.colors = np.random.rand(51, 3)\n",
    "            \n",
    "    def _prepare_pcds(self, pcds, y, row_nr=0, col_number=0):\n",
    "        \n",
    "        if not type(pcds) == list:\n",
    "            pcds = [pcds]\n",
    "            y = [y]\n",
    "        \n",
    "        pcds_o3d = [None] * len(pcds)\n",
    "        for i, pcd in enumerate(pcds):\n",
    "            pcd_o3d = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcd))\n",
    "            pcd_o3d.colors = o3d.utility.Vector3dVector(self.colors[y[i]]) \n",
    "            pcd_o3d = pcd_o3d.translate([col_number*2.5, row_nr*1.5, 0])\n",
    "            pcds_o3d[i] = pcd_o3d        \n",
    "        return pcds_o3d\n",
    "    \n",
    "    \n",
    "    def add(self, pcds, row_nr, col_nr=0):\n",
    "        if not type(pcds)==list:\n",
    "            pcds = [pcds]\n",
    "        for i, pcd in enumerate(pcds):\n",
    "            pos = pcd.pos\n",
    "            y = pcd.y - min(pcd.y)\n",
    "            self.add_pcds(pos, y, row_nr+i, col_nr)\n",
    "    \n",
    "    \n",
    "    def add_pcds(self, pcds, y, row_nr, col_nr=0):\n",
    "        self.pcds_o3d += self._prepare_pcds(pcds, y, row_nr=row_nr, col_number=col_nr)\n",
    "\n",
    "        \n",
    "    def show(self):\n",
    "        o3d.visualization.draw_geometries(self.pcds_o3d)\n",
    "\n",
    "\n",
    "vis = VisualizerPCD()\n",
    "\n",
    "\n",
    "# dataset_name = \"Original_2048\"\n",
    "transform = Compose([NormalizeScale(), FixedPoints(2048)])\n",
    "dataset = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", transform=transform, categories=seg_classes)\n",
    "print(imports.dataset_path)\n",
    "pcd1 = dataset[1]\n",
    "pcd2 = dataset[2]\n",
    "pcd3 = [pcd1, pcd2]\n",
    "vis.add(pcd1, 0, 0)\n",
    "vis.add(pcd2, 1, 0)\n",
    "vis.add(pcd3, 0, 1)\n",
    "vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2874\n",
      "Data(x=[2048, 3], y=[2048], pos=[2048, 3], category=[1])\n",
      "[PointCloud with 2048 points.]\n"
     ]
    }
   ],
   "source": [
    "d_custom = ShapeNetCustom(root_dir=Path(\"/home/domsa/workspace/git/rgcnn_pytorch/dataset/Journal/ShapeNetCustom/Original_2048\"), folder=\"test\", transform=FixedPoints(2048))\n",
    "print(len(d_custom))\n",
    "pcustom = d_custom[2873]\n",
    "print(pcustom)\n",
    "\n",
    "vis = VisualizerPCD()\n",
    "vis.add(pcustom, 0, 0)\n",
    "vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GaussianNoiseTransform\n",
    "from utils import Sphere_Occlusion_Transform\n",
    "path = \"final_models\"\n",
    "# model_names = [\"2048_seg_clean.pt\", \"2048_seg_rrbb.pt\", \"2048_seg_eig.pt\", \"2048_seg_gauss_rr_bb.pt\", \"2048_seg_gauss_rr_eig.pt\"]\n",
    "model_names = [\"2048_seg_clean.pt\", \"2048_seg_rrbb.pt\", \"2048_seg_gauss_rr_bb.pt\", \"2048_seg_gauss_rr_eig.pt\",  \"2048_seg_eig.pt\"]\n",
    "model_names = [path + \"/\" + model for model in model_names] \n",
    "num_points = 2048\n",
    "input_dim  = 22\n",
    "\n",
    "\n",
    "F = [128, 512, 1024]  # Outputs size of convolutional filter.\n",
    "K = [6, 5, 3]         # Polynomial orders.\n",
    "M = [512, 128, 50]\n",
    "\n",
    "\n",
    "fp = FixedPoints(2048)\n",
    "ns = NormalizeScale()\n",
    "nr = NormalizeRotation()\n",
    "t_n = Compose([fp, ns])\n",
    "t_r = Compose([fp, ns, RandomRotate(90, 0), RandomRotate(90, 1), RandomRotate(90, 2)])\n",
    "t_g = Compose([fp, ns, GaussianNoiseTransform(mu=0, sigma=0.02)])\n",
    "t_s = Compose([fp, ns, Sphere_Occlusion_Transform(0.25, num_points=2048)])\n",
    "\n",
    "rect_transform = [\n",
    "    Compose([]),\n",
    "    Compose([BoundingBoxRotate()]),\n",
    "    Compose([BoundingBoxRotate()]),\n",
    "    Compose([NormalizeRotation()]),\n",
    "    Compose([NormalizeRotation()])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/final_models/2048_seg_clean.pt\n",
      "/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/final_models/2048_seg_rrbb.pt\n",
      "/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/final_models/2048_seg_gauss_rr_bb.pt\n",
      "/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/final_models/2048_seg_gauss_rr_eig.pt\n",
      "/home/domsa/workspace/git/rgcnn_pytorch/JurnalCode/final_models/2048_seg_eig.pt\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "d_o = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", transform=t_n, categories=seg_classes)\n",
    "d_r = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", transform=t_r, categories=seg_classes)\n",
    "d_g = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", transform=t_g, categories=seg_classes)\n",
    "d_s = ShapeNet(root=f\"{imports.dataset_path}/Journal/ShapeNet/\", transform=t_s, categories=seg_classes)\n",
    "\n",
    "po = d_o[1]\n",
    "pr = d_r[1]\n",
    "pg = d_g[1]\n",
    "ps = d_s[1]\n",
    "\n",
    "vis = VisualizerPCD()\n",
    "\n",
    "input_pcds = [ps, pg, pr, po]\n",
    "\n",
    "vis.add(input_pcds, 0, 0)\n",
    "\n",
    "net = seg_model(2048, F, K, M, input_dim, reg_prior=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for k, model_name in enumerate(model_names):\n",
    "    print(f\"{imports.curr_path}/{model_name}\")\n",
    "    net.load_state_dict(torch.load(f\"{imports.curr_path}/{model_name}\"))\n",
    "    net = net.eval()\n",
    "    net = net.to(device)\n",
    "    for i, pcd in enumerate(input_pcds):\n",
    "        init_pos = pcd.pos\n",
    "        pcd_in = copy.deepcopy(pcd)\n",
    "        pcd_in = rect_transform[k](pcd_in)\n",
    "        pos = pcd_in.pos.unsqueeze(0)\n",
    "        norm = pcd_in.x.unsqueeze(0)\n",
    "        x = torch.cat([pos.type(torch.float32), norm.type(torch.float32)], dim=2)\n",
    "        # cat = pcd.category\n",
    "        cat = torch.tensor(0)\n",
    "        x, cat = x.to(device), cat.to(device)\n",
    "        out, _ , _ = net(x, cat)\n",
    "        y = out.argmax(dim=2)\n",
    "        vis.add_pcds(init_pos, y.squeeze(0).detach().cpu(), i, k+1)\n",
    "\n",
    "vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

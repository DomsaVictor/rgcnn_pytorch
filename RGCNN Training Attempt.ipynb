{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fa46ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  7 12:11:12 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 53%   34C    P8    39W / 340W |    294MiB / 10008MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1311      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1958      G   /usr/bin/gnome-shell               60MiB |\r\n",
      "|    0   N/A  N/A      5726      G   /usr/lib/xorg/Xorg                151MiB |\r\n",
      "|    0   N/A  N/A      5858      G   /usr/bin/gnome-shell               32MiB |\r\n",
      "|    0   N/A  N/A      5940      G   ...mviewer/tv_bin/TeamViewer        6MiB |\r\n",
      "|    0   N/A  N/A     20678      G   /usr/lib/firefox/firefox           15MiB |\r\n",
      "|    0   N/A  N/A     29941      G   /usr/lib/firefox/firefox            3MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cd3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: ModelNet10(3991)\n",
      "Test dataset shape:  ModelNet10(908)\n",
      "Data(pos=[1024, 3], y=[1], normal=[1024, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.transforms import SamplePoints\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.transforms import LinearTransformation\n",
    "from torch_geometric.transforms import GenerateMeshNormals\n",
    "from torch_geometric.transforms import NormalizeScale\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_scatter import scatter_mean\n",
    "import sys\n",
    "\n",
    "## NOTE:\n",
    "# Made it work with ModelNet10 (in folder \"data/ModelNet\") that has only 10 classes\n",
    "# Now I'll try to test it with ModelNet40 (\"data/ModelNet40\") with 40 classes\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Hyper parameters:\n",
    "num_points = 1024    # 1024 seems to be the limit...?\n",
    "batch_size = 32      # not yet used\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "modelnet_num = 10    # 10 or 40\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Choosing device:\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "#                  NO LONGER USED but leave them here...\n",
    "F = [128, 512, 1024]  # Number of graph convolutional filters.\n",
    "K = [6, 5, 3]         # Polynomial orders.\n",
    "M = [512, 128, 10]    # Output dimensionality of fully connected layers.\n",
    "##########################################################################\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "## Data loading:\n",
    "# For ModelNet10 change root to \"data/ModelNet\"   -> 10 classes\n",
    "# For MpdelNet40 change root to \"data/ModelNet40\" -> 40 classes\n",
    "# Don't forget to change accordingly the output layer from the model...\n",
    "transforms = Compose([SamplePoints(num_points, include_normals=True), NormalizeScale()])\n",
    "\n",
    "root = \"data/ModelNet\"+str(modelnet_num)\n",
    "dataset_train = ModelNet(root=root, name=str(modelnet_num), train=True, transform=transforms)\n",
    "dataset_test = ModelNet(root=root, name=str(modelnet_num), train=False, transform=transforms)\n",
    "\n",
    "# Shuffle Data\n",
    "dataset_train = dataset_train.shuffle()\n",
    "dataset_test = dataset_test.shuffle()\n",
    "\n",
    "# Verification...\n",
    "print(f\"Train dataset shape: {dataset_train}\")\n",
    "print(f\"Test dataset shape:  {dataset_test}\")\n",
    "\n",
    "print(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982f90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.utils as utils\n",
    "import torch_geometric.nn.conv as conv\n",
    "\n",
    "class GetGraph(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Creates the weighted adjacency matrix 'W'\n",
    "        Taked directly from RGCNN\n",
    "        \"\"\"\n",
    "        super(GetGraph, self).__init__()\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        point_cloud_transpose = point_cloud.permute(0, 2, 1)\n",
    "        point_cloud_inner = torch.matmul(point_cloud, point_cloud_transpose)\n",
    "        point_cloud_inner = -2 * point_cloud_inner\n",
    "        point_cloud_square = torch.sum(torch.mul(point_cloud, point_cloud), dim=2, keepdim=True)\n",
    "        point_cloud_square_tranpose = point_cloud_square.permute(0, 2, 1)\n",
    "        adj_matrix = point_cloud_square + point_cloud_inner + point_cloud_square_tranpose\n",
    "        adj_matrix = torch.exp(-adj_matrix)\n",
    "        return adj_matrix\n",
    "\n",
    "\n",
    "class GetLaplacian(nn.Module):\n",
    "    def __init__(self, normalize=True):\n",
    "        \"\"\"\n",
    "        Computes the Graph Laplacian from a Weighted Graph\n",
    "        Taken directly from RGCNN - currently not used - might need to find alternatives in PyG for loss function\n",
    "        \"\"\"\n",
    "        super(GetLaplacian, self).__init__()\n",
    "        self.normalize = normalize\n",
    "\n",
    "        def diag(self, mat):\n",
    "        # input is batch x vertices\n",
    "            d = []\n",
    "            for vec in mat:\n",
    "                d.append(torch.diag(vec))\n",
    "            return torch.stack(d)\n",
    "\n",
    "    def forward(self, adj_matrix):\n",
    "        if self.normalize:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            eye = torch.ones_like(D)\n",
    "            eye = self.diag(eye)\n",
    "            D = 1 / torch.sqrt(D)\n",
    "            D = self.diag(D)\n",
    "            L = eye - torch.matmul(torch.matmul(D, adj_matrix), D)\n",
    "        else:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            D = torch.diag(D)\n",
    "            L = D - adj_matrix\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5583d500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = RGCNN_model(num_points, F, K, M)\\n\\nprint(\"Model\\'s state_dict:\")\\nfor param_tensor in model.state_dict():\\n    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\\n\\n# Print optimizer\\'s state_dict\\nprint(\"Optimizer\\'s state_dict:\")\\nfor var_name in optimizer.state_dict():\\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.utils as utils\n",
    "import torch_geometric.nn.conv as conv\n",
    "import torch\n",
    "\n",
    "class RGCNN_model(nn.Module):\n",
    "    def __init__(self, vertice, F, K, M, regularization = 0, dropout = 0):\n",
    "        # verify the consistency w.r.t. the number of layers\n",
    "        assert len(F) == len(K)\n",
    "        super(RGCNN_model, self).__init__()\n",
    "        '''\n",
    "        F := List of Convolutional Layers dimensions\n",
    "        K := List of Chebyshev polynomial degrees\n",
    "        M := List of Fully Connected Layers dimenstions\n",
    "        \n",
    "        Currently the dimensions are 'hardcoded'\n",
    "        '''\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.M = M\n",
    "\n",
    "        self.vertice = vertice\n",
    "        self.regularization = regularization    # gamma from the paper: 10^-9\n",
    "        self.dropout = dropout\n",
    "        self.regularizers = []\n",
    "\n",
    "        # initialize the model layers\n",
    "        self.get_graph = GetGraph()\n",
    "        # self.get_laplacian = GetLaplacian(normalize=True)\n",
    "        self.pool = nn.MaxPool1d(self.vertice)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=self.dropout)\n",
    "\n",
    "        ###################################################################\n",
    "        #                               CHANGE HERE\n",
    "        self.conv1 = conv.ChebConv(6, 128, 6)\n",
    "        self.conv2 = conv.ChebConv(128, 512, 5)\n",
    "        self.conv3 = conv.ChebConv(512, 1024, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, modelnet_num)\n",
    "        ###################################################################\n",
    "\n",
    "        '''\n",
    "        for i in range(len(F)):\n",
    "            if i == 0:\n",
    "                layer = ChebConv(Fin=3, K=K[i], Fout=F[i])\n",
    "            else:\n",
    "                layer = ChebConv(Fin=F[i-1], K=K[i], Fout=F[i])\n",
    "            setattr(self, 'gcn%d'%i, layer)\n",
    "        for i in range(len(M)):\n",
    "            if i==0:\n",
    "                layer = nn.Linear(F[-1], M[i])\n",
    "            else:\n",
    "                layer = nn.Linear(M[i-1], M[i])\n",
    "            setattr(self, 'fc%d'%i, layer)\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.regularizers = []\n",
    "        # forward pass\n",
    "        W   = self.get_graph(x.detach())  # we don't want to compute gradients when building the graph\n",
    "        edge_index, edge_weight = utils.dense_to_sparse(W)\n",
    "        out = self.conv1(x, edge_index, edge_weight)\n",
    "        out = self.relu(out)\n",
    "        edge_index, edge_weight = utils.remove_self_loops(edge_index, edge_weight)\n",
    "        L_edge_index, L_edge_weight = torch_geometric.utils.get_laplacian(edge_index.detach(), edge_weight.detach(), normalization=\"sym\")\n",
    "        L = torch_geometric.utils.to_dense_adj(edge_index=L_edge_index, edge_attr=L_edge_weight)\n",
    "        self.regularizers.append(torch.linalg.norm(torch.matmul(torch.matmul(torch.Tensor.permute(out.detach(), [0, 2, 1]), L), out.detach())))\n",
    "\n",
    "        W   = self.get_graph(out.detach())\n",
    "        edge_index, edge_weight = utils.dense_to_sparse(W)\n",
    "        out = self.conv2(out, edge_index, edge_weight)\n",
    "        out = self.relu(out)\n",
    "        edge_index, edge_weight = utils.remove_self_loops(edge_index, edge_weight)\n",
    "        L_edge_index, L_edge_weight = torch_geometric.utils.get_laplacian(edge_index.detach(), edge_weight.detach(), normalization=\"sym\")\n",
    "        L = torch_geometric.utils.to_dense_adj(edge_index=L_edge_index, edge_attr=L_edge_weight)\n",
    "        self.regularizers.append(torch.linalg.norm(torch.matmul(torch.matmul(torch.Tensor.permute(out.detach(), [0, 2, 1]), L), out.detach())))\n",
    "\n",
    "        W   = self.get_graph(out.detach())\n",
    "        edge_index, edge_weight = utils.dense_to_sparse(W)\n",
    "        out = self.conv3(out, edge_index, edge_weight)\n",
    "        out = self.relu(out)\n",
    "        edge_index, edge_weight = utils.remove_self_loops(edge_index, edge_weight)\n",
    "        L_edge_index, L_edge_weight = torch_geometric.utils.get_laplacian(edge_index.detach(), edge_weight.detach(), normalization=\"sym\")\n",
    "        L = torch_geometric.utils.to_dense_adj(edge_index=L_edge_index, edge_attr=L_edge_weight)\n",
    "        self.regularizers.append(torch.linalg.norm(torch.matmul(torch.matmul(torch.Tensor.permute(out.detach(), [0, 2, 1]), L), out.detach())))\n",
    "\n",
    "        '''\n",
    "        for i in range(len(self.F)):\n",
    "            x = getattr(self, 'gcn%d'%i)(x, L)\n",
    "            print(x)\n",
    "            x = self.relu(x)\n",
    "        '''\n",
    "\n",
    "        out = out.permute(0, 2, 1) # Transpose\n",
    "        out = self.pool(out)\n",
    "        out.squeeze_(2)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        for param in self.fc1.parameters():\n",
    "            self.regularizers.append(torch.linalg.norm(param))\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        for param in self.fc1.parameters():\n",
    "            self.regularizers.append(torch.linalg.norm(param))\n",
    "        out = self.fc3(out)\n",
    "        for param in self.fc1.parameters():\n",
    "            self.regularizers.append(torch.linalg.norm(param))\n",
    "        '''\n",
    "        for i in range(len(self.M)):\n",
    "            x = getattr(self, \"fc%d\"%i)(x)\n",
    "        return x\n",
    "        '''\n",
    "\n",
    "        return out, self.regularizers\n",
    "'''\n",
    "model = RGCNN_model(num_points, F, K, M)\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5521070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Sample: 0, Loss:2.171449661254883 - Predicted class vs Real Cass: 5 <-> 2\n",
      "Epoch: 0, Sample: 100, Loss:2.1387202739715576 - Predicted class vs Real Cass: 5 <-> 9\n",
      "Epoch: 0, Sample: 200, Loss:2.568060874938965 - Predicted class vs Real Cass: 2 <-> 5\n",
      "Epoch: 0, Sample: 300, Loss:2.3621063232421875 - Predicted class vs Real Cass: 2 <-> 3\n",
      "Epoch: 0, Sample: 400, Loss:1.9728541374206543 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 500, Loss:1.2683491706848145 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 600, Loss:0.46476200222969055 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 700, Loss:0.7380685210227966 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 800, Loss:2.010457754135132 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 0, Sample: 900, Loss:1.939794659614563 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 0, Sample: 1000, Loss:2.334803819656372 - Predicted class vs Real Cass: 8 <-> 9\n",
      "Epoch: 0, Sample: 1100, Loss:0.2670452296733856 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 1200, Loss:0.8123376369476318 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 0, Sample: 1300, Loss:1.9829131364822388 - Predicted class vs Real Cass: 8 <-> 7\n",
      "Epoch: 0, Sample: 1400, Loss:2.1260340213775635 - Predicted class vs Real Cass: 7 <-> 2\n",
      "Epoch: 0, Sample: 1500, Loss:1.449695110321045 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 0, Sample: 1600, Loss:1.2010382413864136 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 1700, Loss:0.006627712398767471 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 1800, Loss:2.483022451400757 - Predicted class vs Real Cass: 1 <-> 3\n",
      "Epoch: 0, Sample: 1900, Loss:4.136536121368408 - Predicted class vs Real Cass: 5 <-> 1\n",
      "Epoch: 0, Sample: 2000, Loss:2.073410987854004 - Predicted class vs Real Cass: 5 <-> 4\n",
      "Epoch: 0, Sample: 2100, Loss:1.0918750762939453 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 0, Sample: 2200, Loss:2.1540222405747045e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 2300, Loss:1.5043755769729614 - Predicted class vs Real Cass: 5 <-> 6\n",
      "Epoch: 0, Sample: 2400, Loss:3.1286373138427734 - Predicted class vs Real Cass: 7 <-> 0\n",
      "Epoch: 0, Sample: 2500, Loss:1.4986110272730002e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 2600, Loss:9.585573934600689e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 2700, Loss:0.00046115281293168664 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 0, Sample: 2800, Loss:1.0989223718643188 - Predicted class vs Real Cass: 6 <-> 4\n",
      "Epoch: 0, Sample: 2900, Loss:2.168246030807495 - Predicted class vs Real Cass: 2 <-> 6\n",
      "Epoch: 0, Sample: 3000, Loss:1.738082766532898 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 0, Sample: 3100, Loss:0.9110796451568604 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 0, Sample: 3200, Loss:1.083914875984192 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 0, Sample: 3300, Loss:8.584712028503418 - Predicted class vs Real Cass: 2 <-> 6\n",
      "Epoch: 0, Sample: 3400, Loss:2.244060397060821e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 3500, Loss:1.7311960458755493 - Predicted class vs Real Cass: 2 <-> 8\n",
      "Epoch: 0, Sample: 3600, Loss:0.00667990930378437 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 0, Sample: 3700, Loss:1.0312267022527521e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 3800, Loss:1.739672143230564e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 0, Sample: 3900, Loss:0.020716335624456406 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.530443497870208 ~~~~~~~~~~~\n",
      "Epoch: 1, Sample: 0, Loss:0.005510393995791674 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 100, Loss:0.3714255690574646 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 1, Sample: 200, Loss:1.3853184555046028e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 300, Loss:2.4424099922180176 - Predicted class vs Real Cass: 6 <-> 3\n",
      "Epoch: 1, Sample: 400, Loss:0.001958955079317093 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 500, Loss:0.0695355087518692 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 600, Loss:0.007277755532413721 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 700, Loss:0.11968197673559189 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 800, Loss:0.012561784125864506 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 900, Loss:0.8002806305885315 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 1000, Loss:1.8732351064682007 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 1, Sample: 1100, Loss:8.00916604930535e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 1200, Loss:0.21999679505825043 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 1, Sample: 1300, Loss:0.3704014718532562 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 1400, Loss:2.3266983032226562 - Predicted class vs Real Cass: 4 <-> 2\n",
      "Epoch: 1, Sample: 1500, Loss:1.4746363162994385 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 1, Sample: 1600, Loss:0.00023140935809351504 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 1700, Loss:2.433987901895307e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 1800, Loss:1.6876589059829712 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 1, Sample: 1900, Loss:3.2962148189544678 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 1, Sample: 2000, Loss:1.45416259765625 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 1, Sample: 2100, Loss:0.3831893503665924 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 1, Sample: 2200, Loss:1.8604193883220432e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 2300, Loss:0.6840851306915283 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 1, Sample: 2400, Loss:4.271798610687256 - Predicted class vs Real Cass: 7 <-> 0\n",
      "Epoch: 1, Sample: 2500, Loss:1.8028677004622295e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 2600, Loss:0.021776221692562103 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 2700, Loss:0.030085325241088867 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 1, Sample: 2800, Loss:1.3348820209503174 - Predicted class vs Real Cass: 6 <-> 4\n",
      "Epoch: 1, Sample: 2900, Loss:1.349954605102539 - Predicted class vs Real Cass: 8 <-> 6\n",
      "Epoch: 1, Sample: 3000, Loss:2.566229820251465 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 1, Sample: 3100, Loss:1.7511144876480103 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 1, Sample: 3200, Loss:0.03046114183962345 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 1, Sample: 3300, Loss:0.8717465996742249 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 1, Sample: 3400, Loss:2.5125530100922333e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 3500, Loss:1.9119853973388672 - Predicted class vs Real Cass: 2 <-> 8\n",
      "Epoch: 1, Sample: 3600, Loss:1.1141218237753492e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 1, Sample: 3700, Loss:0.013109210878610611 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 3800, Loss:2.048278929578373e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 1, Sample: 3900, Loss:0.00020824230159632862 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.7085943372588324 ~~~~~~~~~~~\n",
      "Epoch: 2, Sample: 0, Loss:2.0101699647057103e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 100, Loss:1.8591148853302002 - Predicted class vs Real Cass: 1 <-> 9\n",
      "Epoch: 2, Sample: 200, Loss:2.441537617414724e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 300, Loss:1.6254385709762573 - Predicted class vs Real Cass: 9 <-> 3\n",
      "Epoch: 2, Sample: 400, Loss:0.4548153579235077 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 500, Loss:0.022422345355153084 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 600, Loss:0.00015697367780376226 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 700, Loss:0.976259708404541 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 800, Loss:0.008315120823681355 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 900, Loss:0.03708906099200249 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 1000, Loss:0.4341449439525604 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 2, Sample: 1100, Loss:1.2108623650419759e-06 - Predicted class vs Real Cass: 7 <-> 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Sample: 1200, Loss:0.018450412899255753 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 2, Sample: 1300, Loss:0.6101081967353821 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 1400, Loss:3.1962859630584717 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 2, Sample: 1500, Loss:7.69734525680542 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 2, Sample: 1600, Loss:0.21501734852790833 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 1700, Loss:4.63402466266416e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 1800, Loss:1.6243836879730225 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 2, Sample: 1900, Loss:3.439073324203491 - Predicted class vs Real Cass: 6 <-> 1\n",
      "Epoch: 2, Sample: 2000, Loss:0.9963369369506836 - Predicted class vs Real Cass: 5 <-> 4\n",
      "Epoch: 2, Sample: 2100, Loss:0.31989002227783203 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 2, Sample: 2200, Loss:2.0056054381711874e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 2300, Loss:0.43443533778190613 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 2, Sample: 2400, Loss:0.47442427277565 - Predicted class vs Real Cass: 0 <-> 0\n",
      "Epoch: 2, Sample: 2500, Loss:2.104999111907091e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 2600, Loss:0.8971487879753113 - Predicted class vs Real Cass: 6 <-> 2\n",
      "Epoch: 2, Sample: 2700, Loss:1.7823151665652404e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 2, Sample: 2800, Loss:0.5187720060348511 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 2, Sample: 2900, Loss:0.3983288109302521 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 2, Sample: 3000, Loss:0.9446600675582886 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 2, Sample: 3100, Loss:0.3961278200149536 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 2, Sample: 3200, Loss:0.0003271565947216004 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 2, Sample: 3300, Loss:0.6620741486549377 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 2, Sample: 3400, Loss:1.6299602521030465e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 3500, Loss:0.48195546865463257 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 2, Sample: 3600, Loss:0.001298034330829978 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 2, Sample: 3700, Loss:1.6977638779280824e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 3800, Loss:2.2986255316936877e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 2, Sample: 3900, Loss:0.0005743945948779583 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.7551991981959408 ~~~~~~~~~~~\n",
      "Epoch: 3, Sample: 0, Loss:3.1065930670592934e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 100, Loss:9.470292091369629 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 3, Sample: 200, Loss:3.227370500564575 - Predicted class vs Real Cass: 4 <-> 5\n",
      "Epoch: 3, Sample: 300, Loss:1.802168607711792 - Predicted class vs Real Cass: 9 <-> 3\n",
      "Epoch: 3, Sample: 400, Loss:0.0008553647785447538 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 500, Loss:0.03766971826553345 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 600, Loss:1.5736363820906263e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 700, Loss:1.7401489458279684e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 800, Loss:0.0763486698269844 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 3, Sample: 900, Loss:0.051725707948207855 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 3, Sample: 1000, Loss:0.03208640217781067 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 3, Sample: 1100, Loss:3.057638195969048e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 1200, Loss:0.03623903915286064 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 3, Sample: 1300, Loss:0.9254204630851746 - Predicted class vs Real Cass: 0 <-> 7\n",
      "Epoch: 3, Sample: 1400, Loss:2.4940998554229736 - Predicted class vs Real Cass: 3 <-> 2\n",
      "Epoch: 3, Sample: 1500, Loss:0.4135036766529083 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 3, Sample: 1600, Loss:0.0020893863402307034 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 1700, Loss:1.595205162630009e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 1800, Loss:1.4739606380462646 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 3, Sample: 1900, Loss:6.4109721183776855 - Predicted class vs Real Cass: 2 <-> 1\n",
      "Epoch: 3, Sample: 2000, Loss:0.23681162297725677 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 3, Sample: 2100, Loss:0.00529963755980134 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 3, Sample: 2200, Loss:2.7464750473882305e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 2300, Loss:0.5028998255729675 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 3, Sample: 2400, Loss:4.3553547859191895 - Predicted class vs Real Cass: 7 <-> 0\n",
      "Epoch: 3, Sample: 2500, Loss:2.592069449747214e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 2600, Loss:5.887589850317454e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 2700, Loss:2.030574023592635e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 3, Sample: 2800, Loss:1.2776710987091064 - Predicted class vs Real Cass: 6 <-> 4\n",
      "Epoch: 3, Sample: 2900, Loss:4.176955699920654 - Predicted class vs Real Cass: 3 <-> 6\n",
      "Epoch: 3, Sample: 3000, Loss:5.986666202545166 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 3, Sample: 3100, Loss:0.804593026638031 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 3, Sample: 3200, Loss:0.8928689360618591 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 3, Sample: 3300, Loss:0.5547916293144226 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 3, Sample: 3400, Loss:2.789477321130107e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 3500, Loss:9.179418563842773 - Predicted class vs Real Cass: 2 <-> 8\n",
      "Epoch: 3, Sample: 3600, Loss:1.109711547542247e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 3, Sample: 3700, Loss:1.946880729519762e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 3800, Loss:2.1824223495059414e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 3, Sample: 3900, Loss:0.06654186546802521 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.7689802054622902 ~~~~~~~~~~~\n",
      "Epoch: 4, Sample: 0, Loss:0.019861113280057907 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 100, Loss:3.568986654281616 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 4, Sample: 200, Loss:2.7411811061028857e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 300, Loss:1.9426090717315674 - Predicted class vs Real Cass: 4 <-> 3\n",
      "Epoch: 4, Sample: 400, Loss:2.6993388928531203e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 500, Loss:2.0377336113597266e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 600, Loss:1.9284957488707732e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 700, Loss:0.10296107083559036 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 800, Loss:0.014786165207624435 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 4, Sample: 900, Loss:0.05982283875346184 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 4, Sample: 1000, Loss:0.006916773971170187 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 4, Sample: 1100, Loss:1.818284772525658e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 1200, Loss:0.024902360513806343 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 4, Sample: 1300, Loss:0.34298717975616455 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 1400, Loss:1.5578861236572266 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 4, Sample: 1500, Loss:0.7978655695915222 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 4, Sample: 1600, Loss:0.210084930062294 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 1700, Loss:9.851945651462302e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 1800, Loss:2.3400230407714844 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 4, Sample: 1900, Loss:3.474147319793701 - Predicted class vs Real Cass: 3 <-> 1\n",
      "Epoch: 4, Sample: 2000, Loss:1.2117983102798462 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 4, Sample: 2100, Loss:0.14008349180221558 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 4, Sample: 2200, Loss:3.4965953545906814e-06 - Predicted class vs Real Cass: 5 <-> 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Sample: 2300, Loss:0.5051628351211548 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 4, Sample: 2400, Loss:1.299087405204773 - Predicted class vs Real Cass: 7 <-> 0\n",
      "Epoch: 4, Sample: 2500, Loss:2.9952866498206276e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 2600, Loss:1.7407385257683927e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 2700, Loss:0.0002661551407072693 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 4, Sample: 2800, Loss:0.0133324870839715 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 4, Sample: 2900, Loss:3.7547526359558105 - Predicted class vs Real Cass: 3 <-> 6\n",
      "Epoch: 4, Sample: 3000, Loss:6.243284702301025 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 4, Sample: 3100, Loss:1.185569405555725 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 4, Sample: 3200, Loss:0.0003450381918810308 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 4, Sample: 3300, Loss:1.3929448127746582 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 4, Sample: 3400, Loss:3.353124611749081e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 3500, Loss:1.5373839139938354 - Predicted class vs Real Cass: 6 <-> 8\n",
      "Epoch: 4, Sample: 3600, Loss:1.5919065390335163e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 4, Sample: 3700, Loss:2.133254611180746e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 3800, Loss:2.073690211545909e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 4, Sample: 3900, Loss:1.427268385887146 - Predicted class vs Real Cass: 3 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.7649711851666249 ~~~~~~~~~~~\n",
      "Epoch: 5, Sample: 0, Loss:0.00012007710756734014 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 100, Loss:1.0909316539764404 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 5, Sample: 200, Loss:1.7081187024814426e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 300, Loss:1.5419667959213257 - Predicted class vs Real Cass: 4 <-> 3\n",
      "Epoch: 5, Sample: 400, Loss:0.0007162019610404968 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 500, Loss:1.529691508039832e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 600, Loss:2.100783376590698e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 700, Loss:0.04854938015341759 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 800, Loss:0.0018353874329477549 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 900, Loss:0.1258133202791214 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 1000, Loss:0.10418529063463211 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 5, Sample: 1100, Loss:0.00016039496404118836 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 1200, Loss:0.007107834797352552 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 5, Sample: 1300, Loss:0.26122647523880005 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 1400, Loss:1.4135288000106812 - Predicted class vs Real Cass: 6 <-> 2\n",
      "Epoch: 5, Sample: 1500, Loss:2.99775767326355 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 5, Sample: 1600, Loss:0.0037246327847242355 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 1700, Loss:1.9271132259746082e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 1800, Loss:1.0667632818222046 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 5, Sample: 1900, Loss:2.119661808013916 - Predicted class vs Real Cass: 3 <-> 1\n",
      "Epoch: 5, Sample: 2000, Loss:0.8523639440536499 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 5, Sample: 2100, Loss:0.2536614239215851 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 5, Sample: 2200, Loss:3.699907438203809e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 2300, Loss:3.0313644409179688 - Predicted class vs Real Cass: 2 <-> 6\n",
      "Epoch: 5, Sample: 2400, Loss:2.0340709686279297 - Predicted class vs Real Cass: 7 <-> 0\n",
      "Epoch: 5, Sample: 2500, Loss:3.176038944729953e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 2600, Loss:0.028235552832484245 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 2700, Loss:0.00031488912645727396 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 5, Sample: 2800, Loss:0.2581270635128021 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 5, Sample: 2900, Loss:0.3713049590587616 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 5, Sample: 3000, Loss:0.8135325312614441 - Predicted class vs Real Cass: 7 <-> 1\n",
      "Epoch: 5, Sample: 3100, Loss:1.3741254806518555 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 5, Sample: 3200, Loss:0.01980600878596306 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 5, Sample: 3300, Loss:0.6591145992279053 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 5, Sample: 3400, Loss:3.994374765170505e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 3500, Loss:0.3252750337123871 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 5, Sample: 3600, Loss:1.5409185607495601e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 5, Sample: 3700, Loss:2.728256049522315e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 3800, Loss:2.655321623024065e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 5, Sample: 3900, Loss:0.025482401251792908 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.784515159107993 ~~~~~~~~~~~\n",
      "Epoch: 6, Sample: 0, Loss:2.3973882434802363e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 100, Loss:0.8712619543075562 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 6, Sample: 200, Loss:3.3843687106127618e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 300, Loss:2.002950668334961 - Predicted class vs Real Cass: 4 <-> 3\n",
      "Epoch: 6, Sample: 400, Loss:0.024892272427678108 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 500, Loss:0.00017987888713832945 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 600, Loss:2.310016725459718e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 700, Loss:2.0309451429056935e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 800, Loss:1.257982148672454e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 900, Loss:0.011514564044773579 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 1000, Loss:2.78530216217041 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 6, Sample: 1100, Loss:1.4735404647581163e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 1200, Loss:2.4397684228461003e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 6, Sample: 1300, Loss:1.3828353881835938 - Predicted class vs Real Cass: 0 <-> 7\n",
      "Epoch: 6, Sample: 1400, Loss:1.3028377294540405 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 6, Sample: 1500, Loss:0.0165737085044384 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 6, Sample: 1600, Loss:1.6603373751422623e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 1700, Loss:1.95653160517395e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 1800, Loss:0.2531720697879791 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 6, Sample: 1900, Loss:9.286426544189453 - Predicted class vs Real Cass: 2 <-> 1\n",
      "Epoch: 6, Sample: 2000, Loss:0.4201425313949585 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 6, Sample: 2100, Loss:0.0001285530161112547 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 6, Sample: 2200, Loss:3.1133856737142196e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 2300, Loss:0.6387825012207031 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 6, Sample: 2400, Loss:0.003946125041693449 - Predicted class vs Real Cass: 0 <-> 0\n",
      "Epoch: 6, Sample: 2500, Loss:4.022065695608035e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 2600, Loss:1.7641458498474094e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 2700, Loss:1.947789087353158e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 6, Sample: 2800, Loss:0.9845170378684998 - Predicted class vs Real Cass: 6 <-> 4\n",
      "Epoch: 6, Sample: 2900, Loss:0.739789605140686 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 6, Sample: 3000, Loss:2.9716129302978516 - Predicted class vs Real Cass: 0 <-> 1\n",
      "Epoch: 6, Sample: 3100, Loss:1.0570807456970215 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 6, Sample: 3200, Loss:0.00025384195032529533 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 6, Sample: 3300, Loss:0.9514060020446777 - Predicted class vs Real Cass: 6 <-> 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Sample: 3400, Loss:4.048899427289143e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 3500, Loss:0.9636327624320984 - Predicted class vs Real Cass: 3 <-> 8\n",
      "Epoch: 6, Sample: 3600, Loss:1.5676471321057761e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 6, Sample: 3700, Loss:2.8768647553079063e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 3800, Loss:3.1171898626780603e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 6, Sample: 3900, Loss:0.2079339474439621 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.7810072663492859 ~~~~~~~~~~~\n",
      "Epoch: 7, Sample: 0, Loss:3.869297870551236e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 100, Loss:0.1325138807296753 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 7, Sample: 200, Loss:2.1805703909194563e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 300, Loss:0.7834551930427551 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 7, Sample: 400, Loss:2.0924816131591797 - Predicted class vs Real Cass: 6 <-> 2\n",
      "Epoch: 7, Sample: 500, Loss:5.4165964684216306e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 600, Loss:0.00010035650484496728 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 700, Loss:8.18155676824972e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 800, Loss:6.1718933466181625e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 900, Loss:0.5148594975471497 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 1000, Loss:0.3708297312259674 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 7, Sample: 1100, Loss:1.3144716604074347e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 1200, Loss:2.2915912722965004e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 1300, Loss:3.5825767517089844 - Predicted class vs Real Cass: 0 <-> 7\n",
      "Epoch: 7, Sample: 1400, Loss:7.02638578414917 - Predicted class vs Real Cass: 4 <-> 2\n",
      "Epoch: 7, Sample: 1500, Loss:0.03270379826426506 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 7, Sample: 1600, Loss:1.6347868950106204e-05 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 1700, Loss:2.006120212172391e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 1800, Loss:0.8244765996932983 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 7, Sample: 1900, Loss:4.111282825469971 - Predicted class vs Real Cass: 4 <-> 1\n",
      "Epoch: 7, Sample: 2000, Loss:0.6904217600822449 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 7, Sample: 2100, Loss:0.034710127860307693 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 7, Sample: 2200, Loss:3.897999704349786e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 2300, Loss:1.780403971672058 - Predicted class vs Real Cass: 3 <-> 6\n",
      "Epoch: 7, Sample: 2400, Loss:0.25790077447891235 - Predicted class vs Real Cass: 0 <-> 0\n",
      "Epoch: 7, Sample: 2500, Loss:3.0683399927511346e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 2600, Loss:0.8042404055595398 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 2700, Loss:9.97411334537901e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 7, Sample: 2800, Loss:0.8617504835128784 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 7, Sample: 2900, Loss:0.5186175107955933 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 7, Sample: 3000, Loss:1.01223886013031 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 7, Sample: 3100, Loss:0.9823147058486938 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 7, Sample: 3200, Loss:0.00019343590247444808 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 7, Sample: 3300, Loss:0.16427472233772278 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 7, Sample: 3400, Loss:4.871595137956319e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 3500, Loss:1.3652853965759277 - Predicted class vs Real Cass: 6 <-> 8\n",
      "Epoch: 7, Sample: 3600, Loss:1.2725332680929569e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 7, Sample: 3700, Loss:3.352453177285497e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 3800, Loss:3.662105882540345e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 7, Sample: 3900, Loss:0.5645087957382202 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.791029817088449 ~~~~~~~~~~~\n",
      "Epoch: 8, Sample: 0, Loss:2.3417023840011097e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 100, Loss:0.13544496893882751 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 8, Sample: 200, Loss:2.242421487608226e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 300, Loss:0.5600054264068604 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 8, Sample: 400, Loss:1.9802648694167146e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 500, Loss:0.1310841292142868 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 600, Loss:2.5266735974582843e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 700, Loss:1.0597410664558993e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 800, Loss:2.4112325718306238e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 900, Loss:0.00013136910274624825 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 1000, Loss:0.0009144743089564145 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 8, Sample: 1100, Loss:1.6332948007402592e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 1200, Loss:2.7421172035246855e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 8, Sample: 1300, Loss:1.7267483472824097 - Predicted class vs Real Cass: 3 <-> 7\n",
      "Epoch: 8, Sample: 1400, Loss:3.0812482833862305 - Predicted class vs Real Cass: 4 <-> 2\n",
      "Epoch: 8, Sample: 1500, Loss:0.4856019914150238 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 8, Sample: 1600, Loss:2.171295363950776e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 1700, Loss:2.1200987703196006e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 1800, Loss:1.347954273223877 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 8, Sample: 1900, Loss:2.957091808319092 - Predicted class vs Real Cass: 2 <-> 1\n",
      "Epoch: 8, Sample: 2000, Loss:0.22668766975402832 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 8, Sample: 2100, Loss:0.01924419403076172 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 8, Sample: 2200, Loss:3.925596956833033e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 2300, Loss:0.8181939125061035 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 8, Sample: 2400, Loss:2.8796093463897705 - Predicted class vs Real Cass: 7 <-> 0\n",
      "Epoch: 8, Sample: 2500, Loss:3.4598319871292915e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 2600, Loss:1.8405813762001344e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 2700, Loss:0.16663725674152374 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 8, Sample: 2800, Loss:0.7573115229606628 - Predicted class vs Real Cass: 6 <-> 4\n",
      "Epoch: 8, Sample: 2900, Loss:1.5810467004776 - Predicted class vs Real Cass: 3 <-> 6\n",
      "Epoch: 8, Sample: 3000, Loss:2.1904096603393555 - Predicted class vs Real Cass: 0 <-> 1\n",
      "Epoch: 8, Sample: 3100, Loss:0.7392471432685852 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 8, Sample: 3200, Loss:0.02586371637880802 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 8, Sample: 3300, Loss:0.587832510471344 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 8, Sample: 3400, Loss:3.162391294608824e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 3500, Loss:0.6306454539299011 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 8, Sample: 3600, Loss:0.0024051961954683065 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 8, Sample: 3700, Loss:3.344288870721357e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 3800, Loss:3.096756699960679e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 8, Sample: 3900, Loss:1.5664476156234741 - Predicted class vs Real Cass: 3 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.8133299924830869 ~~~~~~~~~~~\n",
      "Epoch: 9, Sample: 0, Loss:1.1959824405494146e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 100, Loss:2.408360242843628 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 9, Sample: 200, Loss:2.66017445937905e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 300, Loss:5.643336772918701 - Predicted class vs Real Cass: 6 <-> 3\n",
      "Epoch: 9, Sample: 400, Loss:0.2014899104833603 - Predicted class vs Real Cass: 2 <-> 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Sample: 500, Loss:0.42821091413497925 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 600, Loss:2.784862999760662e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 700, Loss:1.615988480807573e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 800, Loss:0.001014389330521226 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 900, Loss:0.00017559988191351295 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 1000, Loss:3.350326733198017e-05 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 9, Sample: 1100, Loss:1.4716670193593018e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 1200, Loss:2.503867335690302e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 9, Sample: 1300, Loss:2.045642614364624 - Predicted class vs Real Cass: 0 <-> 7\n",
      "Epoch: 9, Sample: 1400, Loss:3.920804023742676 - Predicted class vs Real Cass: 4 <-> 2\n",
      "Epoch: 9, Sample: 1500, Loss:8.357370376586914 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 9, Sample: 1600, Loss:0.05331650748848915 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 1700, Loss:2.5703270694066305e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 1800, Loss:1.268621563911438 - Predicted class vs Real Cass: 8 <-> 3\n",
      "Epoch: 9, Sample: 1900, Loss:8.022706031799316 - Predicted class vs Real Cass: 4 <-> 1\n",
      "Epoch: 9, Sample: 2000, Loss:2.0557689666748047 - Predicted class vs Real Cass: 3 <-> 4\n",
      "Epoch: 9, Sample: 2100, Loss:0.13618725538253784 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 9, Sample: 2200, Loss:4.208957307128003e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 2300, Loss:1.091489315032959 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 9, Sample: 2400, Loss:0.0829404890537262 - Predicted class vs Real Cass: 0 <-> 0\n",
      "Epoch: 9, Sample: 2500, Loss:3.627128990046913e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 2600, Loss:2.32670004152169e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 2700, Loss:2.2446374714490958e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 9, Sample: 2800, Loss:0.8767033219337463 - Predicted class vs Real Cass: 6 <-> 4\n",
      "Epoch: 9, Sample: 2900, Loss:0.41816991567611694 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 9, Sample: 3000, Loss:2.612419605255127 - Predicted class vs Real Cass: 0 <-> 1\n",
      "Epoch: 9, Sample: 3100, Loss:1.1485118865966797 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 9, Sample: 3200, Loss:0.04083998128771782 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 9, Sample: 3300, Loss:4.488293170928955 - Predicted class vs Real Cass: 2 <-> 6\n",
      "Epoch: 9, Sample: 3400, Loss:4.2733763621072285e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 3500, Loss:1.0639387369155884 - Predicted class vs Real Cass: 3 <-> 8\n",
      "Epoch: 9, Sample: 3600, Loss:2.2340364012052305e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 9, Sample: 3700, Loss:3.553422175173182e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 3800, Loss:3.5643538467411418e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 9, Sample: 3900, Loss:0.06925494968891144 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.8195940866950638 ~~~~~~~~~~~\n",
      "Epoch: 10, Sample: 0, Loss:0.0523625910282135 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 100, Loss:0.11248479783535004 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 10, Sample: 200, Loss:3.0498206342599588e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 300, Loss:1.5020537376403809 - Predicted class vs Real Cass: 4 <-> 3\n",
      "Epoch: 10, Sample: 400, Loss:1.69131308211945e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 500, Loss:4.17359524362837e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 600, Loss:7.917591574368998e-05 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 700, Loss:0.038258641958236694 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 800, Loss:4.255260500940494e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 900, Loss:2.735091038630344e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 1000, Loss:0.23668619990348816 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 10, Sample: 1100, Loss:2.092314389301464e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 1200, Loss:3.27922020915139e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 10, Sample: 1300, Loss:0.41245198249816895 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 1400, Loss:2.050527811050415 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 10, Sample: 1500, Loss:0.1827126294374466 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 10, Sample: 1600, Loss:0.0005674601998180151 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 1700, Loss:2.9187344807724003e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 1800, Loss:0.8550770282745361 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 10, Sample: 1900, Loss:2.3718931674957275 - Predicted class vs Real Cass: 9 <-> 1\n",
      "Epoch: 10, Sample: 2000, Loss:0.5777278542518616 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 10, Sample: 2100, Loss:0.11005832254886627 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 10, Sample: 2200, Loss:5.0109238145523705e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 2300, Loss:1.3894011974334717 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 10, Sample: 2400, Loss:0.6239356398582458 - Predicted class vs Real Cass: 0 <-> 0\n",
      "Epoch: 10, Sample: 2500, Loss:5.249323749012547e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 2600, Loss:2.1162466055102414e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 2700, Loss:2.678353894225438e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 10, Sample: 2800, Loss:2.9715168476104736 - Predicted class vs Real Cass: 3 <-> 4\n",
      "Epoch: 10, Sample: 2900, Loss:1.5392595529556274 - Predicted class vs Real Cass: 2 <-> 6\n",
      "Epoch: 10, Sample: 3000, Loss:1.3857685327529907 - Predicted class vs Real Cass: 0 <-> 1\n",
      "Epoch: 10, Sample: 3100, Loss:0.36380064487457275 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 10, Sample: 3200, Loss:0.5075342655181885 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 10, Sample: 3300, Loss:0.021672170609235764 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 10, Sample: 3400, Loss:4.573824298859108e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 3500, Loss:2.050328016281128 - Predicted class vs Real Cass: 7 <-> 8\n",
      "Epoch: 10, Sample: 3600, Loss:2.8937442948517855e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 10, Sample: 3700, Loss:0.6951295733451843 - Predicted class vs Real Cass: 4 <-> 5\n",
      "Epoch: 10, Sample: 3800, Loss:3.961604306823574e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 10, Sample: 3900, Loss:0.24968048930168152 - Predicted class vs Real Cass: 8 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.8005512402906539 ~~~~~~~~~~~\n",
      "Epoch: 11, Sample: 0, Loss:8.407548193645198e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 100, Loss:5.086891174316406 - Predicted class vs Real Cass: 2 <-> 9\n",
      "Epoch: 11, Sample: 200, Loss:4.38808183389483e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 300, Loss:1.8487333059310913 - Predicted class vs Real Cass: 6 <-> 3\n",
      "Epoch: 11, Sample: 400, Loss:3.944114723708481e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 500, Loss:0.02041173353791237 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 600, Loss:0.3115580677986145 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 700, Loss:2.040718982243561e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 800, Loss:2.2404528863262385e-05 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 900, Loss:0.918097198009491 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 1000, Loss:0.0002648823137860745 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 11, Sample: 1100, Loss:2.0839061107835732e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 1200, Loss:0.015286927111446857 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 11, Sample: 1300, Loss:0.04538106545805931 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 1400, Loss:4.0341010093688965 - Predicted class vs Real Cass: 1 <-> 2\n",
      "Epoch: 11, Sample: 1500, Loss:1.5160531997680664 - Predicted class vs Real Cass: 2 <-> 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Sample: 1600, Loss:0.00020793650764971972 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 1700, Loss:0.9411947727203369 - Predicted class vs Real Cass: 9 <-> 2\n",
      "Epoch: 11, Sample: 1800, Loss:1.41150963306427 - Predicted class vs Real Cass: 3 <-> 3\n",
      "Epoch: 11, Sample: 1900, Loss:1.8631551265716553 - Predicted class vs Real Cass: 3 <-> 1\n",
      "Epoch: 11, Sample: 2000, Loss:0.4412958025932312 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 11, Sample: 2100, Loss:1.4096112251281738 - Predicted class vs Real Cass: 3 <-> 8\n",
      "Epoch: 11, Sample: 2200, Loss:6.666233275609557e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 2300, Loss:0.8703680634498596 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 11, Sample: 2400, Loss:3.361557173775509e-05 - Predicted class vs Real Cass: 0 <-> 0\n",
      "Epoch: 11, Sample: 2500, Loss:5.145224804437021e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 2600, Loss:2.9226716833363753e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 2700, Loss:3.2953253139567096e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 11, Sample: 2800, Loss:0.1383461356163025 - Predicted class vs Real Cass: 4 <-> 4\n",
      "Epoch: 11, Sample: 2900, Loss:0.6711716055870056 - Predicted class vs Real Cass: 6 <-> 6\n",
      "Epoch: 11, Sample: 3000, Loss:5.100909233093262 - Predicted class vs Real Cass: 0 <-> 1\n",
      "Epoch: 11, Sample: 3100, Loss:3.5634548664093018 - Predicted class vs Real Cass: 4 <-> 6\n",
      "Epoch: 11, Sample: 3200, Loss:0.5400950908660889 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 11, Sample: 3300, Loss:1.8597184419631958 - Predicted class vs Real Cass: 9 <-> 6\n",
      "Epoch: 11, Sample: 3400, Loss:5.723452431993792e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 3500, Loss:0.2797117531299591 - Predicted class vs Real Cass: 8 <-> 8\n",
      "Epoch: 11, Sample: 3600, Loss:4.043681656185072e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 11, Sample: 3700, Loss:5.061577212472912e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 3800, Loss:5.2321493058116175e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 11, Sample: 3900, Loss:1.4779751300811768 - Predicted class vs Real Cass: 3 <-> 8\n",
      "~~~~~~~~~ CORRECT: 0.8048108243547983 ~~~~~~~~~~~\n",
      "Epoch: 12, Sample: 0, Loss:3.574644551918027e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 12, Sample: 100, Loss:0.008103522472083569 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 12, Sample: 200, Loss:3.4149895782320527e-06 - Predicted class vs Real Cass: 5 <-> 5\n",
      "Epoch: 12, Sample: 300, Loss:4.384098529815674 - Predicted class vs Real Cass: 6 <-> 3\n",
      "Epoch: 12, Sample: 400, Loss:3.323930968690547e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 12, Sample: 500, Loss:3.905538505932782e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 12, Sample: 600, Loss:3.2014459065976553e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 12, Sample: 700, Loss:1.987487394217169e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 12, Sample: 800, Loss:0.026306331157684326 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 12, Sample: 900, Loss:4.112171609449433e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 12, Sample: 1000, Loss:3.4612191939231707e-06 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 12, Sample: 1100, Loss:2.65540870714176e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 12, Sample: 1200, Loss:4.545138381217839e-06 - Predicted class vs Real Cass: 1 <-> 1\n",
      "Epoch: 12, Sample: 1300, Loss:0.6312146186828613 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 12, Sample: 1400, Loss:3.8037900924682617 - Predicted class vs Real Cass: 6 <-> 2\n",
      "Epoch: 12, Sample: 1500, Loss:0.2335251271724701 - Predicted class vs Real Cass: 9 <-> 9\n",
      "Epoch: 12, Sample: 1600, Loss:3.348906375322258e-06 - Predicted class vs Real Cass: 7 <-> 7\n",
      "Epoch: 12, Sample: 1700, Loss:2.9622740385093493e-06 - Predicted class vs Real Cass: 2 <-> 2\n",
      "Epoch: 12, Sample: 1800, Loss:6.4033355712890625 - Predicted class vs Real Cass: 7 <-> 3\n",
      "Epoch: 12, Sample: 1900, Loss:2.2705330848693848 - Predicted class vs Real Cass: 8 <-> 1\n",
      "Epoch: 12, Sample: 2000, Loss:0.37935349345207214 - Predicted class vs Real Cass: 4 <-> 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "directory = now.strftime(\"%d_%m_%y_%H:%M:%S\")\n",
    "parent_directory = \"/home/alex/Alex_pyt_geom/Models\"\n",
    "path = os.path.join(parent_directory, directory)\n",
    "os.mkdir(path)\n",
    "\n",
    "# Training\n",
    "\n",
    "# PATH = \"/home/alex/Alex_pyt_geom/Models/model\"\n",
    "model_number = 5                # Change this acording to the model you want to load\n",
    "model = RGCNN_model(num_points, F, K, M, dropout=0.6)\n",
    "\n",
    "# model.load_state_dict(torch.load(path + '/model' + str(model_number) + '.pt'))\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "def get_loss(y, labels, regularization, regularizers):\n",
    "    cross_entropy_loss = loss(y, labels)\n",
    "    s = torch.sum(torch.as_tensor(regularizers))\n",
    "    regularization *= s\n",
    "    l = cross_entropy_loss + regularization\n",
    "    return l\n",
    "    \n",
    "correct_percentage_list = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    #dataset_train = dataset_train.shuffle()\n",
    "    correct = 0\n",
    "    for i, data in enumerate(dataset_train):\n",
    "        # make sure the gradients are empty\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Data preparation \n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred, regularizers = model(x)     # (1 * 40)\n",
    "        \n",
    "        class_pred = torch.argmax(y_pred.squeeze(0))  # (1)  \n",
    "        correct += int((class_pred == y).sum())       # to compute the accuracy for each epoch\n",
    "        \n",
    "\n",
    "        # loss and backward\n",
    "        ###################################################################################\n",
    "        #                           CrossEntropyLoss\n",
    "        # This WORKS but I am testing the other way...\n",
    "        # l = loss(y_pred, y)   # one value\n",
    "        # l.backward()          # update gradients\n",
    "        ###################################################################################\n",
    "       \n",
    "        l = get_loss(y_pred, y, regularization=1e-9, regularizers=regularizers)\n",
    "        l.backward()\n",
    "\n",
    "        # optimisation\n",
    "        optimizer.step()\n",
    "        \n",
    "            \n",
    "        if i%100==0:\n",
    "            print(f\"Epoch: {epoch}, Sample: {i}, Loss:{l} - Predicted class vs Real Cass: {class_pred} <-> {y.item()}\")\n",
    "            # print(torch.sum(torch.as_tensor(regularizers)))\n",
    "        if epoch%5==0:\n",
    "            torch.save(model.state_dict(), path + '/model' + str(epoch) + '.pt')\n",
    "    print(f\"~~~~~~~~~ CORRECT: {correct / len(dataset_train)} ~~~~~~~~~~~\")\n",
    "    correct_percentage_list.append(correct / len(dataset_train))\n",
    "print(correct_percentage_list)\n",
    "\n",
    "torch.save(model.state_dict(), \"/home/alex/Alex_pyt_geom/Models/final_model.pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred, _ = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        correct += int((class_pred == y).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_percentage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85919859",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        # print(\"Pred: \", class_pred.item(), \"Real: \" , y.item())\n",
    "        correct += int((class_pred == y).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f9783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        \n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred, _ = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        print(\"Pred: \", class_pred.item(), \"Real: \" , y.item())\n",
    "        correct += int((class_pred == y_pred).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.rand([1, 1024, 6])*5+3\n",
    "    x = x.to(device)\n",
    "    y = model(x)\n",
    "    y_class = torch.argmax(y)\n",
    "    print(y)\n",
    "    print(y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348f533",
   "metadata": {},
   "source": [
    "WORK IN PROGRESS!!! \n",
    "Trying to create batches from data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e229a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "length = len(dataset_train)\n",
    "batch_size = 32\n",
    "iterations = np.ceil(length/batch_size)\n",
    "iterations = iterations.astype(int)\n",
    "batched_data = torch.empty([125, 1024, 6])\n",
    "print(dataset_train)\n",
    "print(dataset_train[0])\n",
    "aux = Data()\n",
    "for i in range(iterations):\n",
    "    ob = dataset_train[i:i+batch_size]\n",
    "    pos=torch.empty([0, 3])\n",
    "    y = torch.empty([0])\n",
    "    normal = torch.empty([0, 3])\n",
    "    for data in ob:\n",
    "        pos = torch.cat([pos, data.pos])\n",
    "        y = torch.cat([y, data.y])\n",
    "        normal = torch.cat([normal, data.normal])\n",
    "    batch_data[i] = Data(pos=pos, y=y, normal=normal)\n",
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pos.shape)\n",
    "#print(pos)\n",
    "print(len(batch_data))\n",
    "Batched_data = torch.empty([125, 1024, 6])\n",
    "BATCHED_DATA = []\n",
    "for i in range(125):\n",
    "    # print(batch_data[i].pos)\n",
    "    pos = torch.empty([32, 1024, 3])\n",
    "    y = torch.empty([32, 1])\n",
    "    normal = torch.empty([32, 1024, 3])\n",
    "    for i in range(batch_size):\n",
    "        pos[i] = batch_data[i].pos[num_points*i:num_points*i+1024]\n",
    "        y[i] = batch_data[i].y[i]\n",
    "        normal[i] = batch_data[i].normal[num_points*i:num_points*i+1024]\n",
    "    BATCH = Data(pos=pos, y=y, normal=normal)\n",
    "    BATCHED_DATA.append(BATCH)\n",
    "    # Batched_data[i] = Data(pos=pos, y=y, normal=normal)\n",
    "print(pos.shape)\n",
    "print(normal.shape)\n",
    "print(y.shape)\n",
    "print(len(BATCHED_DATA))\n",
    "for data in BATCHED_DATA:\n",
    "    print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

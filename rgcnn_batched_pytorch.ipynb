{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fa46ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 10 09:53:57 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   54C    P3    N/A /  N/A |    911MiB /  4040MiB |     32%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1521      G   /usr/lib/xorg/Xorg                 28MiB |\n",
      "|    0   N/A  N/A      2148      G   /usr/bin/gnome-shell               65MiB |\n",
      "|    0   N/A  N/A      6744      G   /usr/lib/xorg/Xorg                365MiB |\n",
      "|    0   N/A  N/A      6968      G   /usr/bin/gnome-shell               48MiB |\n",
      "|    0   N/A  N/A      7499      G   ...AAAAAAAAA= --shared-files       45MiB |\n",
      "|    0   N/A  N/A      7700      G   /usr/lib/firefox/firefox          149MiB |\n",
      "|    0   N/A  N/A      7750      G   ...AAAAAAAAA= --shared-files       36MiB |\n",
      "|    0   N/A  N/A      7827      G   ...AAAAAAAAA= --shared-files       69MiB |\n",
      "|    0   N/A  N/A     11181      G   ...AAAAAAAAA= --shared-files       95MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cd3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: ModelNet10(3991)\n",
      "Test dataset shape:  ModelNet10(908)\n",
      "Data(pos=[50, 3], y=[1], normal=[50, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.transforms import SamplePoints\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_geometric.transforms import LinearTransformation\n",
    "from torch_geometric.transforms import GenerateMeshNormals\n",
    "from torch_geometric.transforms import NormalizeScale\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_scatter import scatter_mean\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "## NOTE:\n",
    "# Made it work with ModelNet10 (in folder \"data/ModelNet\") that has only 10 classes\n",
    "# Now I'll try to test it with ModelNet40 (\"data/ModelNet40\") with 40 classes\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Choosing device:\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Hyper parameters:\n",
    "num_points = 50     # 1024 seems to be the limit...?\n",
    "batch_size = 32      # not yet used\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "##########################################################################\n",
    "#                  NO LONGER USED but leave them here...\n",
    "F = [128, 512, 1024]  # Number of graph convolutional filters.\n",
    "K = [6, 5, 3]  # Polynomial orders.\n",
    "M = [512, 128, 10]  # Output dimensionality of fully connected layers.\n",
    "##########################################################################\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "## Data loading:\n",
    "# For ModelNet10 change root to \"data/ModelNet\"   -> 10 classes\n",
    "# For MpdelNet40 change root to \"data/ModelNet40\" -> 40 classes\n",
    "# Don't forget to change accordingly the output layer from the model...\n",
    "transforms = Compose([SamplePoints(num_points, include_normals=True), NormalizeScale()])\n",
    "dataset_train = ModelNet(root=\"rgcnn_pytorch/data/ModelNet10\", name='10', train=True, transform=transforms)\n",
    "dataset_test = ModelNet(root=\"rgcnn_pytorch/data/ModelNet10\", name='10', train=False, transform=transforms)\n",
    "\n",
    "# Shuffle Data\n",
    "dataset_train = dataset_train.shuffle()\n",
    "dataset_test = dataset_test.shuffle()\n",
    "\n",
    "# Verification...\n",
    "print(f\"Train dataset shape: {dataset_train}\")\n",
    "print(f\"Test dataset shape:  {dataset_test}\")\n",
    "\n",
    "print(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982f90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.utils as utils\n",
    "import torch_geometric.nn.conv as conv\n",
    "\n",
    "class GetGraph(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Creates the weighted adjacency matrix 'W'\n",
    "        Taked directly from RGCNN\n",
    "\n",
    "        input:\n",
    "            point_cloud: shape = [batch_size * sample_number, n]\n",
    "        output:\n",
    "            adj_matrix:  shape = [batch_size, sample_number, sample_number]\n",
    "        \"\"\"\n",
    "        super(GetGraph, self).__init__()\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        total_points = point_cloud.shape[0]\n",
    "        curr_batch_size = int(total_points/num_points)\n",
    "        point_cloud = point_cloud.reshape(curr_batch_size, num_points, -1)\n",
    "\n",
    "        point_cloud_transpose = point_cloud.permute(0, 2, 1)\n",
    "        point_cloud_inner = torch.matmul(point_cloud, point_cloud_transpose)\n",
    "        point_cloud_inner = -2 * point_cloud_inner\n",
    "        point_cloud_square = torch.sum(torch.mul(point_cloud, point_cloud), dim=2, keepdim=True)\n",
    "        point_cloud_square_tranpose = point_cloud_square.permute(0, 2, 1)\n",
    "        adj_matrix = point_cloud_square + point_cloud_inner + point_cloud_square_tranpose\n",
    "        adj_matrix = torch.exp(-adj_matrix)\n",
    "        return adj_matrix\n",
    "\n",
    "\n",
    "class GetLaplacian(nn.Module):\n",
    "    def __init__(self, normalize=True):\n",
    "        \"\"\"\n",
    "        Computes the Graph Laplacian from a Weighted Graph\n",
    "        Taken directly from RGCNN - currently not used - might need to find alternatives in PyG for loss function\n",
    "        \"\"\"\n",
    "        super(GetLaplacian, self).__init__()\n",
    "        self.normalize = normalize\n",
    "\n",
    "        def diag(self, mat):\n",
    "        # input is batch x vertices\n",
    "            d = []\n",
    "            for vec in mat:\n",
    "                d.append(torch.diag(vec))\n",
    "            return torch.stack(d)\n",
    "\n",
    "    def forward(self, adj_matrix):\n",
    "        if self.normalize:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            eye = torch.ones_like(D)\n",
    "            eye = self.diag(eye)\n",
    "            D = 1 / torch.sqrt(D)\n",
    "            D = self.diag(D)\n",
    "            L = eye - torch.matmul(torch.matmul(D, adj_matrix), D)\n",
    "        else:\n",
    "            D = torch.sum(adj_matrix, dim=1)\n",
    "            D = torch.diag(D)\n",
    "            L = D - adj_matrix\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5583d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.bias \t torch.Size([128])\n",
      "conv1.lins.0.weight \t torch.Size([128, 6])\n",
      "conv1.lins.1.weight \t torch.Size([128, 6])\n",
      "conv1.lins.2.weight \t torch.Size([128, 6])\n",
      "conv1.lins.3.weight \t torch.Size([128, 6])\n",
      "conv1.lins.4.weight \t torch.Size([128, 6])\n",
      "conv1.lins.5.weight \t torch.Size([128, 6])\n",
      "conv2.bias \t torch.Size([512])\n",
      "conv2.lins.0.weight \t torch.Size([512, 128])\n",
      "conv2.lins.1.weight \t torch.Size([512, 128])\n",
      "conv2.lins.2.weight \t torch.Size([512, 128])\n",
      "conv2.lins.3.weight \t torch.Size([512, 128])\n",
      "conv2.lins.4.weight \t torch.Size([512, 128])\n",
      "conv3.bias \t torch.Size([1024])\n",
      "conv3.lins.0.weight \t torch.Size([1024, 512])\n",
      "conv3.lins.1.weight \t torch.Size([1024, 512])\n",
      "conv3.lins.2.weight \t torch.Size([1024, 512])\n",
      "fc1.weight \t torch.Size([512, 1024])\n",
      "fc1.bias \t torch.Size([512])\n",
      "fc2.weight \t torch.Size([128, 512])\n",
      "fc2.bias \t torch.Size([128])\n",
      "fc3.weight \t torch.Size([40, 128])\n",
      "fc3.bias \t torch.Size([40])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]}]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.utils as utils\n",
    "import torch_geometric.nn.conv as conv\n",
    "\n",
    "class RGCNN_model(nn.Module):\n",
    "    def __init__(self, vertice, F, K, M, regularization = 0, dropout = 0):\n",
    "        # verify the consistency w.r.t. the number of layers\n",
    "        assert len(F) == len(K)\n",
    "        super(RGCNN_model, self).__init__()\n",
    "        '''\n",
    "        F := List of Convolutional Layers dimensions\n",
    "        K := List of Chebyshev polynomial degrees\n",
    "        M := List of Fully Connected Layers dimenstions\n",
    "        \n",
    "        Currently the dimensions are 'hardcoded'\n",
    "        '''\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.M = M\n",
    "\n",
    "        self.vertice = vertice\n",
    "        self.regularization = regularization\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # initialize the model layers\n",
    "        self.get_graph = GetGraph()\n",
    "        self.get_laplacian = GetLaplacian(normalize=True)\n",
    "        self.pool = nn.MaxPool1d(vertice)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        ###################################################################\n",
    "        #                                 CHANGE HERE \n",
    "        self.conv1 = conv.ChebConv(6, 128, 6)\n",
    "        self.conv2 = conv.ChebConv(128, 512, 5)\n",
    "        self.conv3 = conv.ChebConv(512, 1024, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 40)\n",
    "        ###################################################################\n",
    "        '''\n",
    "        for i in range(len(F)):\n",
    "            if i == 0:\n",
    "                layer = ChebConv(Fin=3, K=K[i], Fout=F[i])\n",
    "            else:\n",
    "                layer = ChebConv(Fin=F[i-1], K=K[i], Fout=F[i])\n",
    "            setattr(self, 'gcn%d'%i, layer)\n",
    "        for i in range(len(M)):\n",
    "            if i==0:\n",
    "                layer = nn.Linear(F[-1], M[i])\n",
    "            else:\n",
    "                layer = nn.Linear(M[i-1], M[i])\n",
    "            setattr(self, 'fc%d'%i, layer)\n",
    "        '''\n",
    "\n",
    "    def batched_dense_to_sparse(self, W):\n",
    "        '''\n",
    "            Function to transform a batched graph matrix into sparse format\n",
    "            input:\n",
    "                dense graph matrix of size ()\n",
    "\n",
    "            output: \n",
    "                edge_index\n",
    "                enge_weight\n",
    "        '''\n",
    "        edges = [utils.dense_to_sparse(graph) for graph in W]\n",
    "        edge_index = torch.zeros([32, 2, num_points * num_points])\n",
    "        edge_weight = torch.zeros([32, 1, num_points * num_points])\n",
    "        for i, edge in enumerate(edges):\n",
    "            edge_index[i] = torch.tensor(edge[0])\n",
    "            edge_weight[i] = torch.tensor(edge[1])\n",
    "        edge_index = edge_index.reshape(2, 32 * num_points * num_points)\n",
    "        edge_weight = edge_weight.reshape(32 * num_points * num_points)\n",
    "        return edge_index, edge_weigh\n",
    "\n",
    "\n",
    "    def forward(self, x, batch):\n",
    "        # forward pass\n",
    "        W   = self.get_graph(x.detach())  # we don't want to compute gradients when building the graph\n",
    "        edges = [utils.dense_to_sparse(graph) for graph in W]\n",
    "        edge_index = torch.zeros([32, 2, num_points*num_points]).to(device)\n",
    "        edge_weight = torch.zeros([32, 1, num_points*num_points]).to(device)\n",
    "        for i, edge in enumerate(edges):\n",
    "            edge_index[i] = torch.tensor(edge[0]).to(device)\n",
    "            edge_weight[i] = torch.tensor(edge[1]).to(device)\n",
    "        edge_index = edge_index.reshape(2, 32 * num_points*num_points).to(device)\n",
    "        edge_weight = edge_weight.reshape(32 * num_points*num_points).to(device)\n",
    "        \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).to(device)\n",
    "        edge_weight = torch.tensor(edge_weight, dtype=torch.float).to(device)\n",
    "        x = torch.tensor(x, dtype=torch.float).to(device)\n",
    "        \n",
    "        out = self.conv1(x, edge_index, edge_weight, batch=batch)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        W   = self.get_graph(out.detach())\n",
    "        edges = [utils.dense_to_sparse(graph) for graph in W]\n",
    "        edge_index = torch.zeros([32, 2, num_points*num_points]).to(device)\n",
    "        edge_weight = torch.zeros([32, 1, num_points*num_points]).to(device)\n",
    "        for i, edge in enumerate(edges):\n",
    "            edge_index[i] = torch.tensor(edge[0]).to(device)\n",
    "            edge_weight[i] = torch.tensor(edge[1]).to(device)\n",
    "        edge_index = edge_index.reshape(2, 32 * num_points*num_points).to(device)\n",
    "        edge_weight = edge_weight.reshape(32 * num_points*num_points).to(device)\n",
    "        \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).to(device)\n",
    "        edge_weight = torch.tensor(edge_weight, dtype=torch.float).to(device)\n",
    "        out = torch.tensor(out, dtype=torch.float).to(device)\n",
    "\n",
    "        out = self.conv2(out, edge_index, edge_weight, batch=batch)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        W   = self.get_graph(out.detach())\n",
    "        edges = [utils.dense_to_sparse(graph) for graph in W]\n",
    "        edge_index = torch.zeros([32, 2, num_points*num_points]).to(device)\n",
    "        edge_weight = torch.zeros([32, 1, num_points*num_points]).to(device)\n",
    "        for i, edge in enumerate(edges):\n",
    "            edge_index[i] = torch.tensor(edge[0]).to(device)\n",
    "            edge_weight[i] = torch.tensor(edge[1]).to(device)\n",
    "        edge_index = edge_index.reshape(2, 32 * num_points*num_points).to(device)\n",
    "        edge_weight = edge_weight.reshape(32 * num_points*num_points).to(device)\n",
    "        \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).to(device)\n",
    "        edge_weight = torch.tensor(edge_weight, dtype=torch.float).to(device)\n",
    "        out = torch.tensor(out, dtype=torch.float).to(device)\n",
    "        \n",
    "        out = self.conv3(out, edge_index, edge_weight, batch=batch)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        '''\n",
    "        for i in range(len(self.F)):\n",
    "            x = getattr(self, 'gcn%d'%i)(x, L)\n",
    "            print(x)\n",
    "            x = self.relu(x)\n",
    "        '''\n",
    "        # curr_batch_size = int(out.shape[0]/50)\n",
    "        out = out.reshape([-1, 50, 1024])\n",
    "\n",
    "        out = out.permute(0, 2, 1) # Transpose\n",
    "        out = self.pool(out)\n",
    "        out.squeeze_(2)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "        '''\n",
    "        for i in range(len(self.M)):\n",
    "            x = getattr(self, \"fc%d\"%i)(x)\n",
    "        return x\n",
    "        '''\n",
    "\n",
    "model = RGCNN_model(num_points, F, K, M)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5521070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12232/2487681434.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index[i] = torch.tensor(edge[0]).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_weight[i] = torch.tensor(edge[1]).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(edge_index, dtype=torch.long).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_weight = torch.tensor(edge_weight, dtype=torch.float).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index[i] = torch.tensor(edge[0]).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_weight[i] = torch.tensor(edge[1]).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(edge_index, dtype=torch.long).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_weight = torch.tensor(edge_weight, dtype=torch.float).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out = torch.tensor(out, dtype=torch.float).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index[i] = torch.tensor(edge[0]).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_weight[i] = torch.tensor(edge[1]).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(edge_index, dtype=torch.long).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_weight = torch.tensor(edge_weight, dtype=torch.float).to(device)\n",
      "/tmp/ipykernel_12232/2487681434.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out = torch.tensor(out, dtype=torch.float).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Sample: 0, Loss:0.13235673308372498\n",
      "Y predicted: torch.Size([32, 40]), Y label: torch.Size([32])\n",
      "Predicted class: tensor([0, 6, 5, 7, 2, 9, 2, 2, 2, 3, 6, 9, 6, 7, 6, 2, 9, 8, 2, 1, 2, 5, 8, 2,\n",
      "        5, 9, 2, 2, 0, 9, 9, 7], device='cuda:0')\n",
      "Real Class:      tensor([0, 6, 5, 7, 2, 9, 2, 2, 2, 3, 6, 9, 1, 7, 6, 2, 9, 8, 2, 1, 2, 5, 8, 2,\n",
      "        5, 9, 2, 2, 0, 9, 9, 7], device='cuda:0')  \n",
      "Epoch: 0, Sample: 100, Loss:0.13669681549072266\n",
      "Y predicted: torch.Size([32, 40]), Y label: torch.Size([32])\n",
      "Predicted class: tensor([7, 7, 9, 5, 1, 2, 8, 1, 8, 7, 6, 9, 4, 9, 8, 3, 8, 9, 5, 8, 7, 2, 6, 7,\n",
      "        5, 1, 9, 8, 6, 2, 3, 2], device='cuda:0')\n",
      "Real Class:      tensor([7, 7, 9, 5, 1, 2, 8, 1, 8, 7, 6, 9, 4, 9, 8, 3, 8, 9, 5, 8, 7, 2, 4, 7,\n",
      "        5, 1, 9, 8, 4, 2, 3, 2], device='cuda:0')  \n",
      "~~~~~~~~~ CORRECT: 0.9285 ~~~~~~~~~~~\n",
      "Epoch: 1, Sample: 0, Loss:0.048259370028972626\n",
      "Y predicted: torch.Size([32, 40]), Y label: torch.Size([32])\n",
      "Predicted class: tensor([8, 1, 2, 0, 7, 2, 7, 2, 9, 7, 2, 4, 1, 9, 5, 7, 5, 2, 5, 5, 4, 0, 7, 1,\n",
      "        8, 1, 2, 7, 5, 1, 4, 1], device='cuda:0')\n",
      "Real Class:      tensor([8, 1, 2, 0, 7, 2, 7, 2, 9, 7, 2, 4, 1, 9, 5, 7, 5, 2, 5, 5, 4, 0, 7, 1,\n",
      "        8, 1, 2, 7, 5, 1, 4, 1], device='cuda:0')  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12232/1578700114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# make sure the gradients are empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch_geometric/transforms/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch_geometric/transforms/sample_points.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "correct_percentage_list = []\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    for i, data in enumerate(loader_train):\n",
    "        # make sure the gradients are empty\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Data preparation \n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        # x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        # x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred = model(x, data.batch)     # (32 * 40)\n",
    "        class_pred = torch.argmax(y_pred.squeeze(0), dim=1)  # (1)  \n",
    "        correct += int((class_pred == y).sum())       # to compute the accuracy for each epoch\n",
    "        \n",
    "        # loss and backward\n",
    "        l = loss(y_pred, y)   # one value\n",
    "        l.backward()          # update gradients\n",
    "        \n",
    "        # optimisation\n",
    "        optimizer.step()\n",
    "    \n",
    "        if i%100==0:\n",
    "            print(f\"Epoch: {epoch}, Sample: {i}, Loss:{l}\")\n",
    "            print(f\"Y predicted: {y_pred.shape}, Y label: {y.shape}\")\n",
    "            print(f\"Predicted class: {class_pred}\")\n",
    "            print(f\"Real Class:      {y}  \")\n",
    "    print(f\"~~~~~~~~~ CORRECT: {correct /(len(loader_train)* batch_size)} ~~~~~~~~~~~\")\n",
    "    correct_percentage_list.append(correct / len(dataset_train))\n",
    "print(correct_percentage_list)\n",
    "\n",
    "torch.save(model.state_dict(), \"/home/alex/Alex_pyt_geom/models\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        correct += int((class_pred == y).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85919859",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        # print(\"Pred: \", class_pred.item(), \"Real: \" , y.item())\n",
    "        correct += int((class_pred == y).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset_test:\n",
    "        \n",
    "        pos = data.pos        # (num_points * 3)   \n",
    "        normals = data.normal # (num_points * 3)\n",
    "        x = torch.cat([pos, normals], dim=1)   # (num_points * 6)\n",
    "        x = x.unsqueeze(0)    # (1 * num_points * 6)     the first dimension may be used for batching?\n",
    "        x = x.type(torch.float32)  # other types of data may be unstable\n",
    "\n",
    "        y = data.y              # (1)\n",
    "        y = y.type(torch.long)  # required by the loss function\n",
    "        \n",
    "        x = x.to(device)      # to CUDA if available\n",
    "        y = y.to(device)\n",
    "     \n",
    "        # Forward pass\n",
    "        y_pred = model(x)     # (1 * 40)\n",
    "\n",
    "        class_pred = torch.argmax(y_pred)\n",
    "        print(\"Pred: \", class_pred.item(), \"Real: \" , y.item())\n",
    "        correct += int((class_pred == y_pred).sum())\n",
    "\n",
    "    print(f\"Correct percentage : {correct / len(dataset_test)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.rand([1, 1024, 6])*5+3\n",
    "    x = x.to(device)\n",
    "    y = model(x)\n",
    "    y_class = torch.argmax(y)\n",
    "    print(y)\n",
    "    print(y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348f533",
   "metadata": {},
   "source": [
    "WORK IN PROGRESS!!! \n",
    "Trying to create batches from data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e229a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "length = len(dataset_train)\n",
    "batch_size = 32\n",
    "iterations = np.ceil(length/batch_size)\n",
    "iterations = iterations.astype(int)\n",
    "batched_data = torch.empty([125, 1024, 6])\n",
    "print(dataset_train)\n",
    "print(dataset_train[0])\n",
    "aux = Data()\n",
    "for i in range(iterations):\n",
    "    ob = dataset_train[i:i+batch_size]\n",
    "    pos=torch.empty([0, 3])\n",
    "    y = torch.empty([0])\n",
    "    normal = torch.empty([0, 3])\n",
    "    for data in ob:\n",
    "        pos = torch.cat([pos, data.pos])\n",
    "        y = torch.cat([y, data.y])\n",
    "        normal = torch.cat([normal, data.normal])\n",
    "    batch_data[i] = Data(pos=pos, y=y, normal=normal)\n",
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pos.shape)\n",
    "#print(pos)\n",
    "print(len(batch_data))\n",
    "Batched_data = torch.empty([125, 1024, 6])\n",
    "BATCHED_DATA = []\n",
    "for i in range(125):\n",
    "    # print(batch_data[i].pos)\n",
    "    pos = torch.empty([32, 1024, 3])\n",
    "    y = torch.empty([32, 1])\n",
    "    normal = torch.empty([32, 1024, 3])\n",
    "    for i in range(batch_size):\n",
    "        pos[i] = batch_data[i].pos[num_points*i:num_points*i+1024]\n",
    "        y[i] = batch_data[i].y[i]\n",
    "        normal[i] = batch_data[i].normal[num_points*i:num_points*i+1024]\n",
    "    BATCH = Data(pos=pos, y=y, normal=normal)\n",
    "    BATCHED_DATA.append(BATCH)\n",
    "    # Batched_data[i] = Data(pos=pos, y=y, normal=normal)\n",
    "print(pos.shape)\n",
    "print(normal.shape)\n",
    "print(y.shape)\n",
    "print(len(BATCHED_DATA))\n",
    "for data in BATCHED_DATA:\n",
    "    print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
